---
title: "Linear Regression"
output: github_document
---

```{r}
library(tidyverse)
library(p8105.datasets)
```


# Load and clean the Airbnb Data

```{r}
data("nyc_airbnb")

nyc_airbnb = 
  nyc_airbnb |> 
  mutate(stars = review_scores_location / 2) |> 
  rename(
    borough = neighbourhood_group,
    neighborhood = neighbourhood) |> 
  filter(borough != "Staten Island") |> 
  select(price, stars, borough, neighborhood, room_type)

```


Lets fit a Model

```{r}
fit = lm(price ~ stars + borough, data = nyc_airbnb)

nyc_airbnb = 
  nyc_airbnb |> 
  mutate(
    borough = fct_infreq(borough),
    room_type = fct_infreq(room_type))

fit = lm(price ~ stars + borough, data = nyc_airbnb)
```


Lets look at the fit:
```{r}
summary(fit)

summary(fit)$coeff

```

Dont do those things ^ instead - Tidy up the output!

```{r}
fit %>% 
  broom::glance()
```
- glance gives you a high level look at the model -- comparing lots of models this is helpful 


Tidy up the coefficients: 
```{r}
fit %>% 
  broom::tidy() %>% 
  mutate(term = str_replace(term, "^borough", "Borough: ")) %>% 
  knitr::kable(digits = 3)

```
- broom tidy makes anything into a tibble -- very useful 


# Fit another model

```{r}

  nyc_airbnb %>% 
  mutate(
    borough = fct_infreq(borough),
    room_type = fct_infreq(room_type))

fit = lm(price ~ stars + borough + room_type, data = nyc_airbnb)

fit %>% 
  broom::tidy()
```


## Quick look at Regression Diagostics 
- mostly boils down to get the residuals and examine them to make sure you dont have any overly skewed/non normal distributions in the residuals 

```{r}
nyc_airbnb %>% 
  modelr::add_residuals(fit) %>% 
  ggplot(aes(x = resid)) +
  geom_density() +
  xlim(-100, 500)

nyc_airbnb %>% 
  modelr::add_residuals(fit) %>% 
  ggplot(aes(x = borough, y = resid)) +
  geom_violin() 


nyc_airbnb %>% 
  modelr::add_residuals(fit) %>% 
  ggplot(aes(x = stars, y = resid)) +
  geom_point() 
```
** you can fit a model on one dataset and then use the model on another dataset to see how it works 

## Hypothesis test for a categorical predictor 

lets fit a Null and Alternative Hypothesis model

```{r}
fit_null = lm(price ~ stars + borough, data = nyc_airbnb)
fit_alt = lm(price ~ stars + borough + room_type, data = nyc_airbnb)

anova(fit_null, fit_alt) %>% 
  broom::tidy()
```


## Borough-Level Difference

```{r}
fit =  lm(price ~ stars * borough + room_type * borough, data = nyc_airbnb) 

fit %>% 
  broom::tidy()

```

We need to fit 4 models (1 for each borough):

```{r}
## Create the airbnb_lm function for next step
airbnb_lm = function(df) {
  lm(price ~ stars + room_type, data = df)
}

nyc_airbnb %>% 
  nest(df = -borough) %>% 
  mutate(
    models = map(df, airbnb_lm),
    results = map(models, broom::tidy)
  ) %>% 
  select(borough, results) %>% 
  unnest(results) %>% 
  select(borough, term, estimate) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>% 
  knitr::kable(digits = 2)


```
this code creates a handy little table - not for "formal" analysis but very useful


Lets do the same thing just this time with creating an "Anonymous Function": 
```{r}

nyc_airbnb %>% 
  nest(df = -borough) %>% 
  mutate(
    models = map(df, \(df) lm(price ~ stars + room_type, data = df)),
    results = map(models, broom::tidy)
  ) %>% 
  select(borough, results) %>% 
  unnest(results) %>% 
  select(borough, term, estimate) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>% 
  knitr::kable(digits = 2)

```
In this code: 
mutate(
## models = map(df, \(df) lm(price ~ stars + borough, data = df)),
  -- this mutate step is the only thing changing to create the "anonymous function" intended to mimic a whole function that you created and named (like what we did above) its doing the same thing as writing the function above (the way shown above is just manually creating the funtion before)
    



## Homicides in Baltimore -- LOGISTIC REGRESSION (binary outcome)

```{r}
baltimore_df = 
  read_csv("data/homicide-data.csv") |> 
  filter(city == "Baltimore") |> 
  mutate(
    resolved = as.numeric(disposition == "Closed by arrest"),
    victim_age = as.numeric(victim_age),
    victim_race = fct_relevel(victim_race, "White")) |> 
  select(resolved, victim_age, victim_race, victim_sex)

view(baltimore_df)
```


fit a logistic regression for this dataframe

```{r}
fit_logistic = 
  baltimore_df |> 
  glm(resolved ~ victim_age + victim_race + victim_sex, 
      data = _, 
      family = binomial()) 
```

Look at model results:
```{r}
fit_logistic %>% 
  broom::tidy()
```

The table below summaries the coefficients from the model fit; because logistic model estimates are log odds ratios, we include a step to compute odds ratios as well.
```{r}
fit_logistic |> 
  broom::tidy() |> 
  mutate(OR = exp(estimate)) |>
  select(term, log_OR = estimate, OR, p.value) |> 
  knitr::kable(digits = 3)
```

